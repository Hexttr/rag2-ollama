# Проблема: Ollama возвращает 502

## Диагностика

### Статус
- ✅ Ollama запущена (порт 11434 слушает)
- ❌ Все запросы возвращают 502 Bad Gateway
- ❌ Даже нативный API `/api/tags` не отвечает (timeout)

### Возможные причины

1. **Ollama запущена, но не готова**
   - Модель не загружена
   - Ollama еще инициализируется
   - Проблема с конфигурацией Ollama

2. **Проблема с версией Ollama**
   - Старая версия не поддерживает OpenAI API
   - Нужно обновить Ollama

3. **Проблема с моделью**
   - Модель `llama3.1:8b` не загружена
   - Нужно загрузить модель: `ollama pull llama3.1:8b`

4. **Проблема с портом/прокси**
   - Возможно, есть прокси между приложением и Ollama
   - Порт заблокирован

## Решения

### 1. Проверьте версию Ollama
```bash
ollama --version
```

### 2. Проверьте загруженные модели
```bash
ollama list
```

### 3. Загрузите модель, если нужно
```bash
ollama pull llama3.1:8b
```

### 4. Перезапустите Ollama
```bash
# Остановите Ollama
# Затем запустите снова
ollama serve
```

### 5. Проверьте, что Ollama работает
```bash
# В браузере или curl
curl http://localhost:11434/api/tags
```

### 6. Проверьте логи Ollama
- Windows: Проверьте логи Ollama в папке установки
- Или запустите Ollama в терминале для просмотра логов

## Альтернативное решение

Если Ollama не работает с OpenAI-совместимым API, можно использовать нативный API Ollama напрямую. Но это потребует изменений в коде.

## Текущий статус

- ✅ Backend запущен
- ✅ Frontend запущен  
- ✅ Документ загружен
- ❌ Индексация не может завершиться из-за ошибок Ollama

## Следующие шаги

1. Проверьте, что модель `llama3.1:8b` загружена
2. Перезапустите Ollama
3. Проверьте версию Ollama (нужна версия с поддержкой OpenAI API)
4. Попробуйте другую модель, если текущая не работает


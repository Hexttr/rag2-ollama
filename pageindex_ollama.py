"""
–ü–∞—Ç—á–∏–Ω–≥ PageIndex –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama –≤–º–µ—Å—Ç–æ OpenAI
"""
import os
import sys
import openai
import asyncio
import logging
from typing import Optional
import httpx

logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
DEFAULT_OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
_ollama_base_url = DEFAULT_OLLAMA_BASE_URL
_ollama_model = DEFAULT_OLLAMA_MODEL
_patched = False
_ollama_client = None
_ollama_async_client = None


def check_ollama_connection(base_url: Optional[str] = None) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
    try:
        url = (base_url or _ollama_base_url).replace('/v1', '')
        response = httpx.get(f"{url}/api/tags", timeout=5.0)
        return response.status_code == 200
    except Exception as e:
        logger.warning(f"Ollama connection check failed: {e}")
        return False


def patch_pageindex_for_ollama(
    base_url: Optional[str] = None,
    model: Optional[str] = None
) -> bool:
    """
    –ü–∞—Ç—á–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ PageIndex –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama
    
    Args:
        base_url: URL Ollama API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é http://localhost:11434/v1)
        model: –ú–æ–¥–µ–ª—å Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é llama3.2)
    
    Returns:
        True –µ—Å–ª–∏ –ø–∞—Ç—á–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω
    """
    global _ollama_base_url, _ollama_model, _patched, _ollama_client, _ollama_async_client
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    new_base_url = base_url or DEFAULT_OLLAMA_BASE_URL
    new_model = model or DEFAULT_OLLAMA_MODEL
    
    # –ï—Å–ª–∏ –ø–∞—Ç—á–∏–Ω–≥ —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –º–æ–¥–µ–ª—å –∏–ª–∏ URL –∏–∑–º–µ–Ω–∏–ª–∏—Å—å, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–∞—Ç—á–∏–Ω–≥
    if _patched:
        if _ollama_base_url != new_base_url or _ollama_model != new_model:
            logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama –∏–∑–º–µ–Ω–∏–ª–∏—Å—å (–±—ã–ª–æ: {_ollama_model}, —Å—Ç–∞–ª–æ: {new_model}), –ø–µ—Ä–µ–ø–∞—Ç—á–∏–≤–∞–µ–º...")
            _patched = False
            _ollama_client = None
            _ollama_async_client = None
        else:
            logger.info(f"PageIndex —É–∂–µ –ø–∞—Ç—á–µ–Ω –¥–ª—è Ollama (model={_ollama_model})")
            return True
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    _ollama_base_url = new_base_url
    _ollama_model = new_model
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    if not check_ollama_connection(_ollama_base_url):
        logger.warning("‚ö†Ô∏è  Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞—Ç—á–∏–Ω–≥...")
    
    try:
        import sys
        from pathlib import Path
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ PageIndex –≤ sys.path –µ—Å–ª–∏ –µ–≥–æ —Ç–∞–º –Ω–µ—Ç
        pageindex_path = Path(__file__).parent / "PageIndex"
        if str(pageindex_path.parent) not in sys.path:
            sys.path.insert(0, str(pageindex_path.parent))
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å utils
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–ø–æ—Ä—Ç–∞
        utils = None
        utils_module_name = None
        
        # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ PageIndex.pageindex
        try:
            from PageIndex.pageindex import utils
            utils_module_name = 'PageIndex.pageindex.utils'
        except ImportError:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç
            try:
                from pageindex import utils
                utils_module_name = 'pageindex.utils'
            except ImportError:
                # –ò—â–µ–º –≤ sys.modules
                for module_name in list(sys.modules.keys()):
                    if module_name.endswith('.utils') and 'pageindex' in module_name:
                        utils = sys.modules[module_name]
                        utils_module_name = module_name
                        break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
        if utils is None:
            try:
                import importlib
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω–∏ –º–æ–¥—É–ª—è
                for module_name in ['PageIndex.pageindex.utils', 'pageindex.utils', 'PageIndex.pageindex.utils']:
                    try:
                        utils = importlib.import_module(module_name)
                        utils_module_name = module_name
                        break
                    except ImportError:
                        continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ utils: {e}")
        
        if utils is None:
            raise ImportError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–æ–¥—É–ª—å utils –∏–∑ PageIndex")
        
        logger.info(f"–ù–∞–π–¥–µ–Ω –º–æ–¥—É–ª—å utils: {utils_module_name}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –¥–ª—è Ollama
        # –í–ê–ñ–ù–û: api_key –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –Ω–µ None
        ollama_client = openai.OpenAI(
            api_key="ollama",  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            base_url=_ollama_base_url
        )
        
        ollama_async_client = openai.AsyncOpenAI(
            api_key="ollama",
            base_url=_ollama_base_url
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∏–µ–Ω—Ç—ã –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–∞—Ç—á–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö
        _ollama_client = ollama_client
        _ollama_async_client = ollama_async_client
        
        # –ü–∞—Ç—á–∏–º ChatGPT_API
        def patched_ChatGPT_API(model=None, prompt=None, api_key=None, chat_history=None):
            """–ü–∞—Ç—á–µ–Ω–∞—è –≤–µ—Ä—Å–∏—è ChatGPT_API –¥–ª—è Ollama"""
            max_retries = 10
            # –ö–†–ò–¢–ò–ß–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            original_model = model
            final_model = _ollama_model
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å OpenAI –º–æ–¥–µ–ª—å—é
            if model and (model.startswith("gpt-") or model.startswith("claude-") or "openai" in model.lower()):
                logger.warning(f"üö´ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ OpenAI –º–æ–¥–µ–ª—å '{model}', –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ '{final_model}'")
                model = final_model
            elif model and model != _ollama_model:
                logger.warning(f"‚ö†Ô∏è –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å '{model}', –∏—Å–ø–æ–ª—å–∑—É–µ–º '{final_model}' –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama")
                model = final_model
            elif model is None:
                model = final_model
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫: '{model}'")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
            if model != _ollama_model:
                logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –º–æ–¥–µ–ª—å '{model}' –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π '{_ollama_model}'! –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º.")
                model = _ollama_model
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Ollama
            client = _ollama_client
            
            for i in range(max_retries):
                try:
                    if chat_history:
                        messages = chat_history.copy()
                        messages.append({"role": "user", "content": prompt})
                    else:
                        messages = [{"role": "user", "content": prompt}]
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                    if model != _ollama_model:
                        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –º–æ–¥–µ–ª—å '{model}' –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å '{_ollama_model}'! –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º.")
                        model = _ollama_model
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    logger.info(f"üîç –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama —Å –º–æ–¥–µ–ª—å—é: '{model}' (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '{_ollama_model}')")
                    logger.debug(f"üìù –ü—Ä–æ–º–ø—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {str(prompt)[:100]}")
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å —Ç–æ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è
                    assert model == _ollama_model, f"–ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '{_ollama_model}', –Ω–æ –ø–æ–ª—É—á–∏–ª–∏ '{model}'"
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
                    logger.debug(f"üì§ –ó–∞–ø—Ä–æ—Å –∫ Ollama: model='{model}', messages_count={len(messages)}")
                    
                    try:
                        response = client.chat.completions.create(
                            model=model,
                            messages=messages,
                            temperature=0,
                            timeout=900  # 15 –º–∏–Ω—É—Ç timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                        )
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                        if hasattr(response, 'model'):
                            logger.debug(f"üì• –û—Ç–≤–µ—Ç –æ—Ç Ollama: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å '{response.model}'")
                            
                    except Exception as api_error:
                        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏
                        error_str = str(api_error)
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API Ollama: {error_str}")
                        if "46.9" in error_str or "memory" in error_str.lower():
                            logger.error(f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: Ollama –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å!")
                            logger.error(f"üö® –ü–µ—Ä–µ–¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: '{model}', –æ–∂–∏–¥–∞–µ–º–∞—è: '{_ollama_model}'")
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–∞ –≤ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏
                            if ":" in model:
                                logger.warning(f"‚ö†Ô∏è –ò–º—è –º–æ–¥–µ–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç ':', –≤–æ–∑–º–æ–∂–Ω–æ Ollama –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ")
                        raise
                    
                    return response.choices[0].message.content
                except Exception as e:
                    logger.warning(f'************* Retrying ({i+1}/{max_retries}) *************')
                    logger.error(f"Error: {e}")
                    if i < max_retries - 1:
                        import time
                        time.sleep(1)
                    else:
                        logger.error('Max retries reached for prompt: ' + str(prompt)[:100])
                        return "Error"
        
        # –ü–∞—Ç—á–∏–º ChatGPT_API_with_finish_reason
        def patched_ChatGPT_API_with_finish_reason(model=None, prompt=None, api_key=None, chat_history=None):
            """–ü–∞—Ç—á–µ–Ω–∞—è –≤–µ—Ä—Å–∏—è ChatGPT_API_with_finish_reason –¥–ª—è Ollama"""
            max_retries = 10
            # –ö–†–ò–¢–ò–ß–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            # —Ç–∞–∫ –∫–∞–∫ –ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å "gpt-4o-2024-11-20" –∏–ª–∏ –¥—Ä—É–≥–æ–π OpenAI –º–æ–¥–µ–ª—å—é
            original_model = model
            final_model = _ollama_model
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å OpenAI –º–æ–¥–µ–ª—å—é
            if model and (model.startswith("gpt-") or model.startswith("claude-") or "openai" in model.lower()):
                logger.warning(f"üö´ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ OpenAI –º–æ–¥–µ–ª—å '{model}', –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ '{final_model}'")
                model = final_model
            elif model and model != _ollama_model:
                logger.warning(f"‚ö†Ô∏è –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å '{model}', –∏—Å–ø–æ–ª—å–∑—É–µ–º '{final_model}' –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama")
                model = final_model
            elif model is None:
                model = final_model
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫: '{model}'")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
            if model != _ollama_model:
                logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –º–æ–¥–µ–ª—å '{model}' –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π '{_ollama_model}'! –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º.")
                model = _ollama_model
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Ollama
            client = _ollama_client
            
            for i in range(max_retries):
                try:
                    if chat_history:
                        messages = chat_history.copy()
                        messages.append({"role": "user", "content": prompt})
                    else:
                        messages = [{"role": "user", "content": prompt}]
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                    if model != _ollama_model:
                        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –º–æ–¥–µ–ª—å '{model}' –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å '{_ollama_model}'! –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–º–µ–Ω—è–µ–º.")
                        model = _ollama_model
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    logger.info(f"üîç –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama —Å –º–æ–¥–µ–ª—å—é: '{model}' (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '{_ollama_model}')")
                    logger.debug(f"üìù –ü—Ä–æ–º–ø—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {str(prompt)[:100]}")
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å —Ç–æ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è
                    assert model == _ollama_model, f"–ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '{_ollama_model}', –Ω–æ –ø–æ–ª—É—á–∏–ª–∏ '{model}'"
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
                    logger.debug(f"üì§ –ó–∞–ø—Ä–æ—Å –∫ Ollama: model='{model}', messages_count={len(messages)}")
                    
                    try:
                        response = client.chat.completions.create(
                            model=model,
                            messages=messages,
                            temperature=0,
                            timeout=900  # 15 –º–∏–Ω—É—Ç timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                        )
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                        if hasattr(response, 'model'):
                            logger.debug(f"üì• –û—Ç–≤–µ—Ç –æ—Ç Ollama: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å '{response.model}'")
                        if hasattr(response, 'usage'):
                            logger.debug(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage}")
                            
                    except Exception as api_error:
                        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏
                        error_str = str(api_error)
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API Ollama: {error_str}")
                        if "46.9" in error_str or "memory" in error_str.lower():
                            logger.error(f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: Ollama –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å!")
                            logger.error(f"üö® –ü–µ—Ä–µ–¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: '{model}', –æ–∂–∏–¥–∞–µ–º–∞—è: '{_ollama_model}'")
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–∞ –≤ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏
                            if ":" in model:
                                logger.warning(f"‚ö†Ô∏è –ò–º—è –º–æ–¥–µ–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç ':', –≤–æ–∑–º–æ–∂–Ω–æ Ollama –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ")
                        raise
                    
                    finish_reason = response.choices[0].finish_reason
                    if finish_reason == "length":
                        return response.choices[0].message.content, "max_output_reached"
                    elif finish_reason == "error":
                        # –ï—Å–ª–∏ finish_reason == "error", –ø—Ä–æ–±—É–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å
                        logger.warning(f"Ollama –≤–µ—Ä–Ω—É–ª finish_reason='error', –ø–æ–≤—Ç–æ—Ä—è—é –∑–∞–ø—Ä–æ—Å ({i+1}/{max_retries})")
                        if i < max_retries - 1:
                            import time
                            time.sleep(1)
                            continue
                        else:
                            logger.error("Max retries reached, finish_reason='error'")
                            return "Error", "error"
                    else:
                        return response.choices[0].message.content, "finished"
                except Exception as e:
                    logger.warning(f'************* Retrying ({i+1}/{max_retries}) *************')
                    logger.error(f"Error: {e}")
                    if i < max_retries - 1:
                        import time
                        time.sleep(1)
                    else:
                        logger.error('Max retries reached for prompt: ' + str(prompt)[:100])
                        return "Error", "error"
        
        # –ü–∞—Ç—á–∏–º ChatGPT_API_async
        async def patched_ChatGPT_API_async(model=None, prompt=None, api_key=None, chat_history=None):
            """–ü–∞—Ç—á–µ–Ω–∞—è –≤–µ—Ä—Å–∏—è ChatGPT_API_async –¥–ª—è Ollama"""
            max_retries = 10
            # –í–ê–ñ–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            final_model = _ollama_model
            if model and model != _ollama_model:
                logger.warning(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å '{model}', –∏—Å–ø–æ–ª—å–∑—É–µ–º '{final_model}' –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ollama")
            model = final_model
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Ollama
            if _ollama_async_client is None:
                logger.error("Ollama async client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω! –ü–∞—Ç—á–∏–Ω–≥ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω.")
                return "Error"
            client = _ollama_async_client
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
            if chat_history:
                messages = chat_history.copy()
                messages.append({"role": "user", "content": prompt})
            else:
                messages = [{"role": "user", "content": prompt}]
            
            for i in range(max_retries):
                try:
                    # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    logger.info(f"üîç –û—Ç–ø—Ä–∞–≤–∫–∞ async –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama —Å –º–æ–¥–µ–ª—å—é: '{model}' (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '{_ollama_model}')")
                    
                    response = await client.chat.completions.create(
                        model=model,
                        messages=messages,
                        temperature=0,
                        timeout=900  # 15 –º–∏–Ω—É—Ç timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                    )
                    return response.choices[0].message.content
                except Exception as e:
                    logger.warning(f'************* Retrying async ({i+1}/{max_retries}) *************')
                    logger.error(f"Error: {e}")
                    if i < max_retries - 1:
                        await asyncio.sleep(1)
                    else:
                        logger.error('Max retries reached for prompt: ' + str(prompt)[:100])
                        return "Error"
        
        # –ü–∞—Ç—á–∏–º count_tokens –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ Ollama
        original_count_tokens = utils.count_tokens
        
        def patched_count_tokens(text, model=None):
            """–ü–∞—Ç—á–µ–Ω–∞—è –≤–µ—Ä—Å–∏—è count_tokens –¥–ª—è Ollama"""
            if not text:
                return 0
            try:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
                return original_count_tokens(text, model)
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–æ–¥–µ–ª—å Ollama –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω–∞ tiktoken),
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä cl100k_base (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ GPT-4)
                import tiktoken
                try:
                    enc = tiktoken.get_encoding("cl100k_base")
                    return len(enc.encode(text))
                except Exception:
                    # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
                    # ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
                    return len(text) // 4
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –º–æ–¥—É–ª–µ
        utils.ChatGPT_API = patched_ChatGPT_API
        utils.ChatGPT_API_with_finish_reason = patched_ChatGPT_API_with_finish_reason
        utils.ChatGPT_API_async = patched_ChatGPT_API_async
        utils.count_tokens = patched_count_tokens
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞—Ç—á–∏–Ω–≥ –ø—Ä–∏–º–µ–Ω–∏–ª—Å—è
        if hasattr(utils, 'ChatGPT_API') and utils.ChatGPT_API == patched_ChatGPT_API:
            logger.info("–ü–∞—Ç—á–∏–Ω–≥ ChatGPT_API –ø—Ä–∏–º–µ–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.warning("–ü–∞—Ç—á–∏–Ω–≥ ChatGPT_API –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω!")
        
        # –¢–∞–∫–∂–µ –ø–∞—Ç—á–∏–º –≤ sys.modules –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –º–æ–¥—É–ª—å —É–∂–µ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω
        if utils_module_name and utils_module_name in sys.modules:
            sys.modules[utils_module_name].ChatGPT_API = patched_ChatGPT_API
            sys.modules[utils_module_name].ChatGPT_API_with_finish_reason = patched_ChatGPT_API_with_finish_reason
            sys.modules[utils_module_name].ChatGPT_API_async = patched_ChatGPT_API_async
            sys.modules[utils_module_name].count_tokens = patched_count_tokens
            logger.info(f"–ü–∞—Ç—á–∏–Ω–≥ –ø—Ä–∏–º–µ–Ω–µ–Ω –∫ sys.modules['{utils_module_name}']")
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ü–∞—Ç—á–∏–º —Ç–∞–∫–∂–µ –≤ page_index, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç "from .utils import *"
        # –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ–ø–∏—Ä—É—é—Ç—Å—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω page_index
        # –ù—É–∂–Ω–æ –ø–∞—Ç—á–∏—Ç—å –í–°–ï –º–æ–¥—É–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ "from .utils import *"
        try:
            # –°–ø–∏—Å–æ–∫ –º–æ–¥—É–ª–µ–π –¥–ª—è –ø–∞—Ç—á–∏–Ω–≥–∞
            modules_to_patch = []
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤—Å–µ –º–æ–¥—É–ª–∏ pageindex –≤ sys.modules
            for module_name in list(sys.modules.keys()):
                if 'pageindex' in module_name.lower() or 'page_index' in module_name.lower():
                    if not module_name.endswith('.page_index_md'):
                        module = sys.modules[module_name]
                        if hasattr(module, 'ChatGPT_API') or hasattr(module, 'ChatGPT_API_with_finish_reason'):
                            modules_to_patch.append((module_name, module))
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            if not modules_to_patch:
                try:
                    import PageIndex.pageindex.page_index as page_index_module
                    modules_to_patch.append(('PageIndex.pageindex.page_index', page_index_module))
                except ImportError:
                    try:
                        import pageindex.page_index as page_index_module
                        modules_to_patch.append(('pageindex.page_index', page_index_module))
                    except ImportError:
                        pass
            
            # –ü–∞—Ç—á–∏–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏
            for module_name, module in modules_to_patch:
                patched_count = 0
                if hasattr(module, 'ChatGPT_API'):
                    module.ChatGPT_API = patched_ChatGPT_API
                    patched_count += 1
                if hasattr(module, 'ChatGPT_API_with_finish_reason'):
                    module.ChatGPT_API_with_finish_reason = patched_ChatGPT_API_with_finish_reason
                    patched_count += 1
                if hasattr(module, 'ChatGPT_API_async'):
                    module.ChatGPT_API_async = patched_ChatGPT_API_async
                    patched_count += 1
                if hasattr(module, 'count_tokens'):
                    module.count_tokens = patched_count_tokens
                    patched_count += 1
                
                if patched_count > 0:
                    logger.info(f"‚úÖ –ü–∞—Ç—á–∏–Ω–≥ –ø—Ä–∏–º–µ–Ω–µ–Ω –∫ {module_name} ({patched_count} —Ñ—É–Ω–∫—Ü–∏–π)")
                else:
                    logger.debug(f"–ú–æ–¥—É–ª—å {module_name} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è –ø–∞—Ç—á–∏–Ω–≥–∞")
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ç—á–∏—Ç—å page_index –º–æ–¥—É–ª–∏: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        _patched = True
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è get_ollama_settings
        global _ollama_settings
        _ollama_settings = {
            'base_url': _ollama_base_url,
            'model': _ollama_model,
            'patched': True
        }
        
        logger.info(f"‚úÖ PageIndex —É—Å–ø–µ—à–Ω–æ –ø–∞—Ç—á–µ–Ω –¥–ª—è Ollama (base_url={_ollama_base_url}, model={_ollama_model})")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ç—á–∏–Ω–≥–µ PageIndex: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def get_ollama_settings():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama"""
    global _ollama_settings
    if not _ollama_settings:
        _ollama_settings = {
            "base_url": _ollama_base_url,
            "model": _ollama_model,
            "patched": _patched
        }
    return _ollama_settings

# ü¶ô –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Ollama —Å PageIndex

## ‚úÖ –î–∞, –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å Ollama!

Ollama –∏–º–µ–µ—Ç **—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —Å OpenAI**, –ø–æ—ç—Ç–æ–º—É –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PageIndex **–±–µ—Å–ø–ª–∞—Ç–Ω–æ** —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.

---

## üöÄ –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama

**Windows:**
```bash
# –°–∫–∞—á–∞—Ç—å —Å https://ollama.com/download
# –ò–ª–∏ —á–µ—Ä–µ–∑ winget
winget install Ollama.Ollama
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

```bash
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è PageIndex:
ollama pull llama3.2          # –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
ollama pull mistral           # –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
ollama pull qwen2.5:14b       # –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (–±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä)
ollama pull gemma2:9b         # –ë—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è

# –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–±—ã—Å—Ç—Ä–∞—è, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–∞—è):
ollama pull llama3.2:1b
```

### 3. –ó–∞–ø—É—Å–∫ Ollama —Å–µ—Ä–≤–µ—Ä–∞

Ollama –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
ollama serve
```

–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã:
```bash
curl http://localhost:11434/api/tags
```

---

## üîß –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è PageIndex –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `pageindex_ollama.py` —Å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏:

```python
# pageindex_ollama.py
import os
import openai
from pageindex.utils import *

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")

def ChatGPT_API_ollama(model=None, prompt=None, api_key="ollama", chat_history=None):
    """
    –ó–∞–º–µ–Ω–∞ ChatGPT_API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama
    """
    if model is None:
        model = OLLAMA_MODEL
    
    max_retries = 10
    client = openai.OpenAI(
        api_key=api_key,  # Ollama –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–ª—é—á, –Ω–æ –Ω—É–∂–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        base_url=OLLAMA_BASE_URL
    )
    
    for i in range(max_retries):
        try:
            if chat_history:
                messages = chat_history
                messages.append({"role": "user", "content": prompt})
            else:
                messages = [{"role": "user", "content": prompt}]
            
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0,
            )
            
            return response.choices[0].message.content
        except Exception as e:
            print(f'************* Retrying ({i+1}/{max_retries}) *************')
            print(f"Error: {e}")
            if i < max_retries - 1:
                import time
                time.sleep(1)
            else:
                return "Error"

async def ChatGPT_API_async_ollama(model=None, prompt=None, api_key="ollama"):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Ollama
    """
    if model is None:
        model = OLLAMA_MODEL
    
    max_retries = 10
    messages = [{"role": "user", "content": prompt}]
    
    for i in range(max_retries):
        try:
            client = openai.AsyncOpenAI(
                api_key=api_key,
                base_url=OLLAMA_BASE_URL
            )
            
            response = await client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0,
            )
            
            return response.choices[0].message.content
        except Exception as e:
            print(f'************* Retrying ({i+1}/{max_retries}) *************')
            print(f"Error: {e}")
            if i < max_retries - 1:
                import asyncio
                await asyncio.sleep(1)
            else:
                return "Error"

def ChatGPT_API_with_finish_reason_ollama(model=None, prompt=None, api_key="ollama", chat_history=None):
    """
    –í–µ—Ä—Å–∏—è —Å finish_reason –¥–ª—è Ollama
    """
    if model is None:
        model = OLLAMA_MODEL
    
    max_retries = 10
    client = openai.OpenAI(
        api_key=api_key,
        base_url=OLLAMA_BASE_URL
    )
    
    for i in range(max_retries):
        try:
            if chat_history:
                messages = chat_history
                messages.append({"role": "user", "content": prompt})
            else:
                messages = [{"role": "user", "content": prompt}]
            
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0,
            )
            
            finish_reason = response.choices[0].finish_reason
            if finish_reason == "length":
                return response.choices[0].message.content, "max_output_reached"
            else:
                return response.choices[0].message.content, "finished"
        except Exception as e:
            print(f'************* Retrying ({i+1}/{max_retries}) *************')
            print(f"Error: {e}")
            if i < max_retries - 1:
                import time
                time.sleep(1)
            else:
                return "Error", "error"
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ (–±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π)

–ú–æ–∂–Ω–æ –Ω–∞–ø—Ä—è–º—É—é –∏–∑–º–µ–Ω–∏—Ç—å `PageIndex/pageindex/utils.py`, –¥–æ–±–∞–≤–∏–≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É Ollama —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.

---

## üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –°–ø–æ—Å–æ–± 1: –ú–æ–Ω–∫–∏-–ø–∞—Ç—á–∏–Ω–≥ (–ø—Ä–æ—Å—Ç–æ–π)

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `run_pageindex_ollama.py`:

```python
# run_pageindex_ollama.py
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º
sys.path.insert(0, os.path.dirname(__file__))

# –ú–æ–Ω–∫–∏-–ø–∞—Ç—á–∏–Ω–≥ —Ñ—É–Ω–∫—Ü–∏–π
from pageindex import utils
from pageindex_ollama import (
    ChatGPT_API_ollama,
    ChatGPT_API_async_ollama,
    ChatGPT_API_with_finish_reason_ollama
)

# –ó–∞–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
utils.ChatGPT_API = ChatGPT_API_ollama
utils.ChatGPT_API_async = ChatGPT_API_async_ollama
utils.ChatGPT_API_with_finish_reason = ChatGPT_API_with_finish_reason_ollama

# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ã—á–Ω—ã–π run_pageindex.py
from pageindex import page_index_main, config

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--pdf_path', type=str, required=True)
    parser.add_argument('--model', type=str, default='llama3.2')
    args = parser.parse_args()
    
    opt = config(
        model=args.model,
        if_add_node_summary='yes',
        if_add_node_id='yes'
    )
    
    result = page_index_main(args.pdf_path, opt)
    
    import json
    output_file = f"{os.path.splitext(args.pdf_path)[0]}_structure.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_file}")
```

### –°–ø–æ—Å–æ–± 2: –ü—Ä—è–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
# example_ollama.py
from pageindex_ollama import ChatGPT_API_ollama
from pageindex import page_index_main, config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
opt = config(
    model='llama3.2',  # –ú–æ–¥–µ–ª—å Ollama
    if_add_node_summary='yes'
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
result = page_index_main('document.pdf', opt)
```

---

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ `.env` —Ñ–∞–π–ª:

```bash
# .env
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.2

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenAI (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è)
USE_OLLAMA=true
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ Ollama –¥–ª—è PageIndex

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –ö–∞—á–µ—Å—Ç–≤–æ | –°–∫–æ—Ä–æ—Å—Ç—å | RAM |
|--------|--------|----------|----------|-----|
| **llama3.2** | 3B | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | 4GB |
| **mistral** | 7B | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | 8GB |
| **qwen2.5:14b** | 14B | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö° | 16GB |
| **gemma2:9b** | 9B | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | 10GB |
| **llama3.1:8b** | 8B | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | 10GB |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ù–∞—á–Ω–∏—Ç–µ —Å `llama3.2` –∏–ª–∏ `mistral` –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏.

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

### 1. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

- ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å **—Ö–æ—Ä–æ—à–æ** –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
- ‚ö†Ô∏è –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å **–Ω–∏–∂–µ**, —á–µ–º —É GPT-4o
- üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ **7B+** –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### 2. –°–∫–æ—Ä–æ—Å—Ç—å

- üêå –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ **–º–µ–¥–ª–µ–Ω–Ω–µ–µ**, —á–µ–º –æ–±–ª–∞—á–Ω—ã–µ API
- ‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ 100 —Å—Ç—Ä–∞–Ω–∏—Ü –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å **10-30 –º–∏–Ω—É—Ç** (vs 2-5 –º–∏–Ω—É—Ç —Å GPT-4o)
- üíª –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–∞—à–µ–≥–æ –∂–µ–ª–µ–∑–∞ (CPU/GPU)

### 3. –ü–∞–º—è—Ç—å

- üíæ –ú–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç RAM/VRAM
- üìä 7B –º–æ–¥–µ–ª—å: ~8-10GB RAM
- üìä 14B –º–æ–¥–µ–ª—å: ~16-20GB RAM
- üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (CUDA)

### 4. JSON —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —Ö—É–∂–µ —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º JSON. –ú–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è:
- –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
- Post-processing –æ—Ç–≤–µ—Ç–æ–≤
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –º–æ—â–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É Ollama:

```python
# test_ollama.py
from pageindex_ollama import ChatGPT_API_ollama

response = ChatGPT_API_ollama(
    model='llama3.2',
    prompt='–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ: —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ Ollama?'
)

print(response)
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: OpenAI vs Ollama

| –ü–∞—Ä–∞–º–µ—Ç—Ä | OpenAI GPT-4o | Ollama (–ª–æ–∫–∞–ª—å–Ω–æ) |
|----------|---------------|-------------------|
| **–°—Ç–æ–∏–º–æ—Å—Ç—å** | üí∞ –ü–ª–∞—Ç–Ω–æ ($0.50-2/–¥–æ–∫) | ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ |
| **–°–∫–æ—Ä–æ—Å—Ç—å** | ‚ö° –ë—ã—Å—Ç—Ä–æ (2-5 –º–∏–Ω) | üêå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ (10-30 –º–∏–Ω) |
| **–ö–∞—á–µ—Å—Ç–≤–æ** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê-‚≠ê‚≠ê‚≠ê‚≠ê |
| **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è** | –ò–Ω—Ç–µ—Ä–Ω–µ—Ç | –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä |
| **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å** | ‚ùå –î–∞–Ω–Ω—ã–µ —É—Ö–æ–¥—è—Ç –≤ –æ–±–ª–∞–∫–æ | ‚úÖ –í—Å–µ –ª–æ–∫–∞–ª—å–Ω–æ |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** | ‚úÖ –õ–µ–≥–∫–æ | ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –∂–µ–ª–µ–∑–æ–º |

---

## üöÄ –ì–æ—Ç–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ

–Ø —Å–æ–∑–¥–∞–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Ollama. –°–º. `pageindex_ollama.py` –∏ `run_pageindex_ollama.py`.

---

## üí° –°–æ–≤–µ—Ç—ã –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU** (–µ—Å–ª–∏ –µ—Å—Ç—å):
   ```bash
   # Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
   ```

2. **–ö—ç—à–∏—Ä—É–π—Ç–µ –∏–Ω–¥–µ–∫—Å—ã** - –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–µ–ª–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑

3. **–ù–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –º–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏** –¥–ª—è –≤–∞–∂–Ω—ã—Ö –∑–∞–¥–∞—á

5. **–ö–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –ø–æ–¥—Ö–æ–¥—ã**:
   - –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è: Ollama (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –º–æ–∂–Ω–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å)
   - –ü–æ–∏—Å–∫: OpenAI (–±—ã—Å—Ç—Ä–æ, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ)

---

*–£—Å–ø–µ—à–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏! ü¶ô*




